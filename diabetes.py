# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/160RR4RXjtCprr71Pe_f9X83Dc5c3_dov
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

data = pd.read_csv('/diabetes_prediction_dataset.csv')
data.drop_duplicates(inplace=True)
print(data)

data["gender"] = data["gender"].map({"Female":"F", "Male":"M", "Other":"Other"})
data["gender"] = data["gender"].map({"F":"F", "M":"M", "Other":data["gender"].mode()[0]})
sns.countplot(x = data["diabetes"], hue=data["gender"])

sns.countplot(x = data["diabetes"], hue=data["smoking_history"])

bins = [0, 20, 30, 40, 50, 60, 70, 80, 90, 100]
labels = ['<20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '90+']
data['age_group'] = pd.cut(data['age'], bins=bins, labels=labels)

# Tạo biểu đồ countplot với cột age_group và hue là diabetes
sns.countplot(x=data['diabetes'], hue=data['age_group'])

# Lọc dữ liệu để chỉ lấy các giá trị thỏa mãn điều kiện HbA1c_level từ 3.5 đến 9 và blood_glucose_level từ 80 đến 300
filtered_data = data[(data['HbA1c_level'] >= 3.5) & (data['HbA1c_level'] <= 9) & (data['blood_glucose_level'] >= 80) & (data['blood_glucose_level'] <= 300)]

# Tạo biểu đồ
sns.catplot(x="HbA1c_level", y="blood_glucose_level", hue="diabetes", kind="bar", data=filtered_data)

# Đặt tên cho trục x, trục y và tiêu đề
plt.xlabel("HbA1c_level")
plt.ylabel("blood_glucose_level")
plt.title("Correlation between HbA1c_level and blood_glucose_level for diabetes")
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import sklearn

data.hist(bins=10, figsize=(10,8))
plt.show()

data['gender'] = data['gender'].map({'Female': 0,'Male': 1, 'Other': 2})
data['smoking_history'] = data['smoking_history'].map({'never': 0,'No Info': 1,'current': 2,'former': 3, 'ever': 4,'not current': 5})
data.dropna(inplace=True)

data['age'] = data['age'].astype(int)
data.head()

# Tách các đặc trưng và nhãn
X = data.drop('diabetes', axis=1)
y = data['diabetes']
print(X)
# Chuẩn hóa dữ liệu
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Tách dữ liệu thành tập huấn luyện và tập kiểm tra
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier

# Xác định đặc trưng quan trọng bằng mô hình Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

feature_importances = pd.Series(rf.feature_importances_, index=data.drop('diabetes', axis=1).columns)
print(feature_importances)

X_change_imp = data.drop(['diabetes','gender','smoking_history'], axis=1)
print(X_change_imp)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_change_imp = scaler.fit_transform(X_change_imp)
print(X_change_imp)

from sklearn.decomposition import PCA
pca = PCA(n_components=6)
X_change_imp = pca.fit_transform(X_change_imp)
print(X_change_imp)

from xgboost import XGBClassifier
import xgboost as xgb
X_train, X_test, y_train, y_test = train_test_split(X_change_imp, y, test_size=0.2, random_state=42)

xgb_model = XGBClassifier(n_estimators=1000, learning_rate=0.07) #1000 vs 0.05
xgb_model.fit(X_train, y_train)

from keras.models import Sequential
from keras.layers import Dense

# Xây dựng mô hình Neural Network
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=6))
model.add(Dense(64, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile mô hình
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Huấn luyện mô hình
model.fit(X_train, y_train, epochs=150, batch_size=64, validation_split=0.2)

# Đánh giá mô hình trên tập kiểm tra
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test accuracy: {accuracy}')

import numpy as np

xgb_preds = xgb_model.predict_proba(X_test)[:, 1]
nn_preds = model.predict(X_test)

# combine predictions using simple averaging
ensemble_preds = (xgb_preds + nn_preds.flatten()) / 2
# convert predictions to binary values (0 or 1)
ensemble_preds = np.round(ensemble_preds)
# evaluate performance on test set
accuracy = np.mean(ensemble_preds == y_test)
print(f'Test accuracy: {accuracy:.5f}')

